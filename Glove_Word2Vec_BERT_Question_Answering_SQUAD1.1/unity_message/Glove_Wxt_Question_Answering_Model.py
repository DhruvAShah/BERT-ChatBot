# -*- coding: utf-8 -*-
"""Glove_Wxt_Question_Answering_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KcWDmrizGcM0H8Gjc7gKEj9jOaoeMeZI

This is Glove Python Model which is trained on the Question Corpous to plot the most similar word embeddings.
Usually people use Glove as the Stnaford 100-6B trained embeddings into there models but this is the model 
which is trained from scratch and hence really useful to creatr your own word embeddings

Author - Dhruv Shah
"""

#Install the Hugging Face Transformers Library for BERT Fine Tune Model
#!pip install transformers

import os
import numpy as np
import spacy
import gensim
import collections
import smart_open
import random
import sys
import torch
import textwrap
import nltk
#nltk.download('punkt')

from nltk.tokenize import sent_tokenize

from glove import Glove
from glove import Corpus


# Set file names for train and test data
test_data_dir = '/home/ubuntu/Glove_Word2Vec_BERT_Question_Answering_SQUAD1.1/Train_DataSet_Corpus'
lee_train_file = test_data_dir + os.sep + 'train_question.txt'
#train_referencepara_file = test_data_dir + os.sep + 'train_referencepara.cor'
#vocab_file = '/home/unity/IVR/ConversationalIvr/utility' + os.sep + 'text8'


def read_corpus(filename):
    delchars = [chr(c) for c in range(256)]
    delchars = [x for x in delchars if not x.isalnum()]
    delchars.remove(' ')
    delchars = ''.join(delchars)

    table = str.maketrans(dict.fromkeys(delchars))

    with open(filename, 'r') as datafile:
        for line in datafile:
            yield line.lower().translate(table).split(' ')

def train_model():
    get_data = read_corpus(lee_train_file)
    corpus_model = Corpus()
    corpus_model.fit(get_data, window=10)

    epochs = 10
    no_threads = 8

    print('Training the GloVe model')
    glove = Glove(no_components=100, learning_rate=0.05)
    glove.fit(corpus_model.matrix, epochs=epochs, no_threads=no_threads, verbose=True)
    glove.add_dictionary(corpus_model.dictionary)
    glove.save('glove.model')


def load_model():
    model_name = '/home/ubuntu/Glove_Word2Vec_BERT_Question_Answering_SQUAD1.1/unity_message/glove.model'
    print('Loading pre-trained GloVe model')
    glove = Glove.load(model_name)
    return glove


def main ():
    """Train the model With Training Question and Answer Corpus
    Model Training is Required when we are are loading new content
    where word matrix have low understanding . for similar content
    no need to train the model again
    """
    #train_model()
    #query = "threads in single inbox"
    words = ['threads', 'single', 'inbox']
    #paratoken=sent_tokenize(query)
    #print (paratoken)
    #query = sys.argv[1]
    glove = load_model()
    for query in words:
        print (glove.most_similar(query, number=5))


if __name__ == "__main__":
        main()

