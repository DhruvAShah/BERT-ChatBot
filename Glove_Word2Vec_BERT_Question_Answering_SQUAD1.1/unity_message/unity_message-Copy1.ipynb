{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "[ 4.5926e-01 -2.1961e-01  2.3668e-01  2.9480e-02 -3.3782e-02 -1.5102e-01\n",
      "  1.2803e-01  3.3457e-01  8.9377e-02  8.4445e-01  5.2618e-01  5.5579e-01\n",
      "  3.6356e-01  7.5972e-02  4.4162e-01 -4.7786e-01 -9.2004e-02  1.7969e-01\n",
      " -1.7835e-01 -6.9549e-02  1.5980e-01 -4.1440e-01 -5.1201e-01 -1.4961e-01\n",
      "  1.1038e-01  1.7055e-01  6.6630e-02  3.0913e-02 -1.5415e-01  4.7514e-01\n",
      " -3.4880e-02 -8.1175e-02 -1.2449e-01  3.4796e-01  3.3504e-01  5.7326e-01\n",
      "  3.0099e-01  2.2629e-01 -1.9616e-01 -8.6075e-02 -2.2984e-01 -2.1100e-01\n",
      "  5.1637e-01 -2.9703e-01  1.5543e-01 -3.9240e-01  1.1993e-01 -3.6973e-01\n",
      "  5.6853e-02 -1.7193e-01  5.1999e-01 -1.1465e-01  1.2658e-01  2.9438e-01\n",
      " -2.3366e-01 -4.5268e-01  2.7601e-01 -3.5656e-01  6.6104e-02  1.0061e-01\n",
      "  9.4015e-02 -2.4633e-01 -3.3964e-02  3.5981e-01  2.6736e-01  8.5726e-02\n",
      " -4.5825e-01 -1.9245e-01  4.2172e-02 -1.4363e-01 -4.1706e-01 -4.2262e-01\n",
      " -4.5954e-02  3.8686e-01 -1.9098e-01  3.3640e-01 -6.0880e-03 -8.5057e-02\n",
      "  8.9079e-01  4.1535e-01 -3.8864e-03  7.5647e-02 -9.2184e-02 -6.1289e-01\n",
      "  1.2406e-01 -9.8022e-01  1.4073e-01  5.8533e-02 -4.5903e-01 -5.6749e-01\n",
      "  1.0673e-01 -1.2141e-01  3.7624e-01  1.4000e-01 -2.4298e-01 -1.3022e-01\n",
      " -3.3912e-01  1.0630e-01  3.8930e-01  7.1063e-03 -3.5597e-03  1.9721e-01\n",
      " -2.9138e-01  6.2492e-02 -2.2506e-01 -4.4733e-01 -3.8278e-01 -5.0421e-01\n",
      "  1.6270e-01 -1.2396e-01  6.2042e-01  2.8976e-01 -3.8343e-01 -4.6981e-02\n",
      "  2.4560e-01  4.5715e-01  2.4796e-01  5.9734e-02  1.8222e-01 -4.3253e-02\n",
      " -6.9521e-02 -1.6915e-01  2.7673e-02 -2.3712e-01  2.1497e-01  3.0073e-01\n",
      "  2.1171e-01 -2.2083e-01  3.4443e-01  1.6376e-02 -2.4512e-01 -5.8163e-01\n",
      " -1.2594e-01  1.8556e-01 -3.5447e-01 -7.9507e-02 -3.5539e-01 -3.2747e-01\n",
      "  1.8424e-01 -1.1164e-01 -5.7166e-01 -2.4728e-01 -2.4912e-01 -1.8039e-01\n",
      "  6.9498e-01  3.8402e-01 -6.9926e-02  6.7077e-02  8.6528e-01  2.4234e-02\n",
      " -3.6129e-01  4.7346e-03 -2.6965e-01 -4.2942e-01 -2.6858e-01  4.5786e-01\n",
      "  3.0242e-01  3.1762e-01 -1.5920e-01  4.3026e-01  2.3744e-01  1.7319e-01\n",
      " -6.2850e-01  1.8576e-01  1.1865e-01  1.1901e-01  2.3690e-01  1.8480e-01\n",
      " -3.6678e-01 -5.0284e-01  3.5679e-01  1.0188e-02  4.9652e-01 -3.0334e-02\n",
      "  1.4707e-01  8.4953e-02  4.8662e-01  3.3584e-01  6.5698e-01 -4.7167e-01\n",
      "  1.7642e-01  8.7152e-02 -4.2054e-01 -1.0641e-01  1.4189e-01  1.5999e-03\n",
      "  4.8206e-01  4.0302e-01 -1.6976e-01 -2.1093e-01  9.5522e-02  1.4033e-01\n",
      " -2.1148e-01  4.9935e-01  1.3170e-02  8.8148e-02 -2.6764e-01 -2.0604e-01\n",
      " -1.1903e-01  3.0513e-01 -9.3624e-01 -2.3879e-01 -4.9508e-02  3.4413e-01\n",
      " -7.9558e-04  3.7142e-01  4.0934e-01 -5.4828e-01 -3.1969e-01  5.8842e-02\n",
      "  1.6794e-01  6.7922e-02  4.3895e-01  4.6270e-02 -2.4436e-02 -5.6194e-01\n",
      "  1.4394e-01  3.5086e-02 -2.3239e-02  1.1325e-01 -1.8664e-01  4.8135e-01\n",
      "  5.6801e-02 -3.2068e-02  2.6263e-01  3.0999e-02 -6.2885e-01 -2.5205e-01\n",
      " -6.1194e-03  2.1940e-01  6.0004e-02  4.5119e-02  4.2376e-01  1.7201e-01\n",
      " -3.0685e-01 -1.8076e-03  8.3536e-02 -1.2161e-01 -1.2585e-01 -4.1227e-01\n",
      "  1.2188e-01  2.0307e-01 -4.9497e-01  3.2790e-01  4.1668e-01  1.5390e-01\n",
      "  1.9193e-01 -5.5301e-02  4.1904e-01 -4.6645e-01 -1.1532e-01 -3.3830e-01\n",
      " -2.1719e-02 -1.5333e-01 -2.4377e-01  8.7398e-01  1.0171e-01  1.6441e-01\n",
      " -8.6569e-02  3.9424e-03  4.1431e-02  4.6519e-01  6.1633e-02 -3.0082e-01\n",
      "  4.4446e-02 -3.6063e-01  2.6018e-01 -1.2936e-01 -4.1767e-02  3.4110e-02\n",
      "  1.8564e-01  2.5569e-01 -1.7700e-01 -1.3173e-02 -5.6486e-01  1.8954e-01\n",
      "  9.3881e-01 -1.8711e-02 -2.0658e-01 -1.9879e-01 -3.2271e-01 -2.4511e-01\n",
      "  5.7252e-01 -2.1396e-02  5.8887e-02 -2.5322e-02  7.5438e-02 -7.3916e-02\n",
      "  2.0141e-01  1.5925e-01  1.5038e-01  4.1651e-01  9.6869e-02  5.0739e-01\n",
      " -2.6561e-01 -6.2601e-01 -1.5822e-01  2.7511e-01  1.7348e-01  2.8332e-02]\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "GLOVE_DIR = os.path.join(\"/home/unity/IVR/ConversationalIvr/utility/\")\n",
    "\n",
    "# first, build index mapping words in the embeddings set\n",
    "# to their embedding vector\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(embeddings_index['asafoetida'])        \n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_extract(query):\n",
    "\n",
    "    query = nlp(query)\n",
    "\n",
    "    entity = []\n",
    "\n",
    "    for token in query:\n",
    "        if token.pos_ == 'PROPN' or token.pos_ == 'NOUN' or token.pos_ ==  'VERB':\n",
    "            entity.append(token.text.lower())\n",
    "    return entity    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb(query):\n",
    "    query1 = query.split(\" \") \n",
    "    query_emb = []\n",
    "    for word in query1:\n",
    "        if word.lower() in embeddings_index:\n",
    "            query_emb.append(embeddings_index[word.lower()])\n",
    "    return np.unique(query_emb, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.038466  -0.039792   0.082747  -0.38923   -0.21431    0.1702\n",
      " -0.025657   0.09578    0.2386    -1.6342     0.14332   -0.037958\n",
      " -0.019583   0.38494    0.097319   0.29697   -0.34523    0.11742\n",
      " -0.024189   0.16013    0.09824    0.12811   -0.17482    0.20976\n",
      " -0.22362   -0.20656    0.24428    0.066875  -0.12594   -0.015706\n",
      "  0.064986   0.4754    -0.055405   0.54286   -0.75188   -0.083218\n",
      "  0.17896    0.073084  -0.3033    -0.17416   -0.17147   -0.1192\n",
      "  0.038308  -0.2066     0.088679  -0.055993   0.361      0.38658\n",
      " -0.055434   0.097699   0.3686    -0.326      0.13023   -0.29897\n",
      " -0.24709    0.051869   0.030422   0.18586   -0.046117  -0.14765\n",
      "  0.35895    0.10094   -0.087822  -0.17514   -0.25403   -0.35855\n",
      "  0.15801   -0.027074   0.12565   -0.17509   -0.13126   -0.13916\n",
      "  0.053628  -0.049429   0.051938  -0.048684   0.071719   0.080952\n",
      " -0.20018   -0.10871   -0.26707   -0.35727    0.3712     0.016709\n",
      " -0.034959  -0.047711   0.0024827  0.10847    0.0089053 -0.14874\n",
      "  0.046014   0.42702   -0.24684    0.12193   -0.27579    0.25844\n",
      " -0.20991   -0.086667   0.14767   -0.17441    0.17054   -0.30868\n",
      " -0.08797   -0.17195   -0.11743    0.12146    0.069268   0.13311\n",
      " -0.13565   -0.24855   -0.0026393 -0.71169   -0.32594   -0.36397\n",
      "  0.053331   0.35714   -0.30035    0.041583  -0.11996   -0.02368\n",
      "  0.016728   0.15869   -0.16491   -0.2782    -0.13788    0.10178\n",
      " -0.24177    0.096347   0.2367     0.20885   -0.28867    0.10772\n",
      "  0.15562   -0.012284  -0.22161   -0.1017     0.1257    -0.29579\n",
      " -0.0089604  0.35075    0.020088   0.020389   0.0038884  0.31869\n",
      " -0.19848    0.060458   0.28148   -0.23499   -0.17035   -0.22323\n",
      "  0.57975    0.26464   -0.10124    0.081058   0.14029    0.066431\n",
      " -0.12212    0.040034   0.027548  -0.1476     0.31438   -0.23046\n",
      "  0.2645    -0.10945   -0.39033    0.1266    -0.030951   0.067389\n",
      "  0.16807    0.22373    0.13502    0.38235   -0.52807    0.54013\n",
      " -0.043062   0.093211   0.045211  -0.24291   -0.49781    0.26425\n",
      "  0.0264     0.14347    0.11763   -0.011614   0.097932  -0.26632\n",
      " -0.22143    0.25156    0.08128    0.10937   -0.12199    0.019255\n",
      " -0.33463   -0.18181    0.064724   0.22921   -0.032425  -0.27295\n",
      "  0.31983    0.16134    0.93692   -0.1214    -0.012617   0.25274\n",
      "  0.24615    0.13214    0.16092    0.20576   -0.051567  -0.3784\n",
      "  0.19761    0.16993   -0.087151   0.026922   0.38035    0.083349\n",
      "  0.24715   -0.1094     0.15459   -0.051741   0.16604   -0.21335\n",
      " -0.030744  -0.14574   -0.50462    0.34825   -0.12343    0.17733\n",
      "  0.2857    -0.30467   -0.15095    0.30346   -0.15678    0.064804\n",
      " -0.073008   0.26499    0.16312    0.11889   -0.63938    0.15598\n",
      " -0.23643    0.59644    0.38748    0.3358    -0.58647    0.12584\n",
      "  0.36144   -0.33622    0.38128   -0.10348    0.18825   -0.33686\n",
      "  0.0058178 -0.1345     0.55511   -0.056443   0.15094   -0.28438\n",
      "  0.025488   0.20392    0.052712  -0.45719    0.089267   0.095469\n",
      " -0.19022   -0.17101   -0.37599   -0.182     -0.065605  -0.061388\n",
      " -0.19467   -0.070368  -0.23977    0.39253   -0.21283    0.17221\n",
      " -1.867     -0.22609    0.53976   -0.3358    -0.48587   -0.050246\n",
      "  0.31694   -0.15536    0.12244    0.38356   -0.1389     0.41886\n",
      "  0.23664   -0.31113    0.045194  -0.20405   -0.21097   -0.11025\n",
      "  0.021766   0.44129    0.32797   -0.33427    0.011807   0.059703 ]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#len(query_emb)\n",
    "print(embeddings_index[\"and\"])\n",
    "print(len(get_emb(\"and and\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = \"Heartiest congratulation on your much awaited promotion, lets celebrate tonight\"\n",
    "str2 = \"why not you pickup my call , call me back whenever you free \"\n",
    "query = \"any thing important\"\n",
    "score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thing']\n",
      "6\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = get_emb(' '.join(entity_extract(str1)))\n",
    "y = get_emb(' '.join(entity_extract(str2)))\n",
    "z = get_emb(' '.join(entity_extract(query)))\n",
    "print(entity_extract(query))\n",
    "print(len(x))\n",
    "print(len(y))\n",
    "print(len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new max = [[0.33048368]] max1 =-1000\n",
      "1 max1 =[[0.33048368]]\n",
      "new max = [[-0.101652]] max1 =[[0.33048368]]\n",
      "new max = [[0.06505415]] max1 =[[0.33048368]]\n",
      "new max = [[0.2252298]] max1 =[[0.33048368]]\n",
      "new max = [[0.14230633]] max1 =[[0.33048368]]\n",
      "new max = [[0.43387663]] max1 =[[0.33048368]]\n",
      "1 max1 =[[0.43387663]]\n",
      "new max = [[0.27472216]] max2 =-1000\n",
      "1 max2 =[[0.27472216]]\n",
      "new max = [[0.12916009]] max2 =[[0.27472216]]\n",
      "new max = [[0.3963106]] max2 =[[0.27472216]]\n",
      "1 max2 =[[0.3963106]]\n"
     ]
    }
   ],
   "source": [
    "doc = -1\n",
    "max1 = -1000\n",
    "max2 = -1000\n",
    "count = 1\n",
    "sent1_max = []\n",
    "sent2_max = []\n",
    "for q in z:\n",
    "    #print(q)\n",
    "    #print(q)\n",
    "    #print(cosine_similarity([x[0]], [q]))\n",
    "    max1 = -1000\n",
    "    max2 = -1000\n",
    "    \n",
    "    for sm in x:\n",
    "        new_max = cosine_similarity([sm],[q])\n",
    "        print(\"new max = \" + str(new_max) + \" max1 =\" + str(max1))\n",
    "        if new_max > max1:\n",
    "            max1 = new_max\n",
    "            if(max1>0.3):\n",
    "                sent1_max.append(max1)\n",
    "            print(str(count) + \" max1 =\" + str(max1))\n",
    "    #max = reduce(lambda a,b: cosine_similarity([a], [q]) if cosine_similarity([a], [q]) > cosine_similarity([b], [q]) else cosine_similarity([b], [q]), x)\n",
    "    #print(max1)\n",
    "    #max2 = -1000\n",
    "    for sm in y:\n",
    "        new_max = cosine_similarity([sm],[q])\n",
    "        print(\"new max = \" + str(new_max) + \" max2 =\" + str(max2))\n",
    "        if new_max > max2:\n",
    "            max2 = new_max\n",
    "            if(max2>0.3):\n",
    "                sent2_max.append(max2)\n",
    "            print(str(count) + \" max2 =\" + str(max2))\n",
    "    #max = reduce(lambda a,b: cosine_similarity([a], [q]) if cosine_similarity([a], [q]) > cosine_similarity([b], [q]) else cosine_similarity([b], [q]), y)\n",
    "    #print(max2)\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.33048368]], dtype=float32), array([[0.43387663]], dtype=float32)]\n",
      "[array([[0.3963106]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sent1_max)\n",
    "print(sent2_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7643603]]\n",
      "[[0.3963106]]\n"
     ]
    }
   ],
   "source": [
    "#cosine_similarity([x[0]], [z[0]])\n",
    "a = reduce(lambda a,b: a+b, sent1_max)\n",
    "b = reduce(lambda a,b: a+b, sent2_max)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if a > b:\n",
    "    doc = 1\n",
    "else:\n",
    "    doc = 2\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom functools import reduce\\nx = get_emb(str1)\\ny = get_emb(str2)\\nz = get_emb(query)\\n#print(x)\\na = reduce(lambda a,b: a+b, x)\\n#print(a)\\n#print(len(a))\\na = a/len(a)\\nb = reduce(lambda a,b: a+b, y)\\nb = b/len(b)\\nc = reduce(lambda a,b: a+b, z)\\nc = c/len(c)\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from functools import reduce\n",
    "x = get_emb(str1)\n",
    "y = get_emb(str2)\n",
    "z = get_emb(query)\n",
    "#print(x)\n",
    "a = reduce(lambda a,b: a+b, x)\n",
    "#print(a)\n",
    "#print(len(a))\n",
    "a = a/len(a)\n",
    "b = reduce(lambda a,b: a+b, y)\n",
    "b = b/len(b)\n",
    "c = reduce(lambda a,b: a+b, z)\n",
    "c = c/len(c)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6732715]]\n",
      "[[0.4380747]]\n"
     ]
    }
   ],
   "source": [
    "#print(cosine_similarity([b], [c]))\n",
    "#print(cosine_similarity([a], [c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set([1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41542643]], dtype=float32)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999999]], dtype=float32)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
